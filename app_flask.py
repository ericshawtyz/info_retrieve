"""
Flask app for GoldenRetriever
The script interfaces with a non-public db

The app may allow 2 methods:
    1. make_query
    2. save_feedback 

To use:
    python app_flask.py -db "db_cnxn_str.txt"
"""
import datetime
import pyodbc
import numpy as np
import pandas as pd
import pandas.io.sql as pds
from flask import Flask, jsonify, request
from waitress import serve
from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, PublicAccess
import argparse
import tarfile
import os

from src.model import GoldenRetriever
from src.kb_handler import kb_handler




"""
Setup
"""
app = Flask(__name__)
parser = argparse.ArgumentParser()
parser.add_argument("-db", "--credentials", dest='dir',
                     default='db_cnxn_str.txt', 
                     help="directory of the pyodbc password string")
args = parser.parse_args()


class InvalidUsage(Exception):
    """
    Raises exception
    https://flask.palletsprojects.com/en/1.1.x/patterns/apierrors/
    """
    status_code = 400

    def __init__(self, message="query endpoint requires arguments: query, kb_name", 
                 status_code=None, payload=None):
        Exception.__init__(self)
        self.message = message
        if status_code is not None:
            self.status_code = status_code
        self.payload = payload

    def to_dict(self):
        rv = dict(self.payload or ())
        rv['message'] = self.message
        return rv

@app.errorhandler(InvalidUsage)
def handle_invalid_usage(error):
    response = jsonify(error.to_dict())
    response.status_code = error.status_code
    return response

def get_last_insert_ids(cursor, inserted_iterable = ['single_string']):
    """
    Get ids of last inserted iterable
    
    args:
    ----
        cursor: pyodbc cursor
        inserted_iterable: iterable of last inserted values
    
    Return:
    ------
        last_insert_ids: (list of ints) list of indices of inserted rows
    
    references:
        https://code.google.com/archive/p/pyodbc/wikis/FAQs.wiki#How_do_I_retrieve_autogenerated%2Fidentity_values%3F
        https://dba.stackexchange.com/questions/81604/how-to-insert-values-in-junction-table-for-many-to-many-relationships
        https://stackoverflow.com/questions/2548493/how-do-i-get-the-id-after-insert-into-mysql-database-with-python
    """
    cursor.execute( "SELECT @@IDENTITY")
    last_insert_id = cursor.fetchall()
    last_insert_id = int(last_insert_id[0][0])
    last_insert_ids = [i for i in range(last_insert_id, last_insert_id-len(inserted_iterable), -1)]
    return last_insert_ids

def extract(lst, idx=0): 
    return [item[idx] for item in lst] 

def init_sql_references(conn):
    """
    Utility function to get references from SQL. 
    The returned objects conveniently identify users based on kb_name or user hashkey
    """
    # get kb_names to kb_id
    kb_ref = pds.read_sql("""SELECT id, kb_name, directory_id  FROM dbo.kb_raw""", conn)
    get_kb_dir_id = kb_ref.loc[:,['kb_name', 'directory_id']].set_index('kb_name').to_dict()['directory_id']
    get_kb_raw_id = kb_ref.loc[:,['kb_name', 'id']].set_index('kb_name').to_dict()['id']

    # get kb permissions
    permissions = pds.read_sql("SELECT hashkey, kb_name, user_id FROM dbo.users \
                                LEFT JOIN dbo.kb_directory ON dbo.users.id = dbo.kb_directory.user_id \
                                LEFT JOIN kb_raw ON dbo.kb_directory.id = dbo.kb_raw.directory_id \
                            ", conn)
    permissions = pd.DataFrame(np.array(permissions), columns = ['hashkey', 'kb_name', 'user_id']).set_index('hashkey')
    
    return get_kb_dir_id, get_kb_raw_id, permissions





"""
Caching
------
Caches the following:
    1. gr: model object to make query
    2. cursor: SQL connection
    3. get_kb_dir_id, get_kb_raw_id: dictionary to retrieve
                                     kb_dir_id and kb_raw_id 
                                     from kb_name (user provided string)
"""
# load the model and knowledge bases
gr = GoldenRetriever()
# gr.restore('./google_use_nrf_pdpa_tuned/variables-0')
kbh = kb_handler()
kbs = kbh.load_sql_kb(cnxn_path = args.dir, kb_names=['PDPA','nrf'])
gr.load_kb(kbs)


# make the SQL connection and cursor
conn = pyodbc.connect(open(args.dir, 'r').read())
cursor = conn.cursor()

get_kb_dir_id, get_kb_raw_id, permissions = init_sql_references(conn)




"""
API endpoints:
--------------
    1. make_query
    2. feedback 
    3. knowledge_base
"""
@app.route("/query", methods=['POST'])
def make_query():
    """
    Main function for User to make requests to. 

    Args:
    -----
        hashkey: (str, optional) identification; intended to be their hashkey 
                                 to manage exclusive knowledge base access.
        query: (str) query string contains their natural question
        kb_name: (str) Name of knowledge base to query
        top_k: (int, default 5) Number of top responses to query. Currently kept at 5

    Return:
    -------
        reply: (list) contains top_k string responses
        query_id: (int) contains id of the request to be used for when they give feedback
    """

    # 1. parse the request and get timestamp
    request_timestamp = datetime.datetime.now()
    request_dict = request.get_json()
    
    if not all([key in ['query', 'kb_name'] for key in request_dict.keys()]):
        raise InvalidUsage()

    HASHKEY = request_dict.get('hashkey')
    query_string = request_dict["query"]
    kb_name = request_dict["kb_name"]
    
    # # Manage KB access
    # try:
    #     if kb_name in permissions.loc[HASHKEY].kb_name:
    #         pass
    #     else:
    #         raise InvalidUsage(f"Unauthorised or unfound kb: {HASHKEY} tried to access {kb_name}")
    # except:
    #     raise InvalidUsage(f"Unrecognized hashkey: {HASHKEY}")



    # 2. model inference
    reply, reply_index = gr.make_query(query_string, 
                                       # top_k=int(top_k), 
                                       top_k = 5,
                                       index=True, kb_name=kb_name)


    # 3. log the request in SQL
    # query log has the following columns
    # id, created_at, query_string, user_id, kb_dir_id, kb_raw_id, Answer1, Answer2, Answer3, Answer4, Answer5
    rowinfo = [request_timestamp, query_string] 
    # append user_id
    logged_user_id = permissions.loc[HASHKEY].user_id.iloc[-1] if HASHKEY in permissions.index else None
    rowinfo.append(logged_user_id) 
    # append kb_dir_id
    rowinfo.append(get_kb_dir_id[kb_name])   
    # append kb_raw_id
    rowinfo.append(get_kb_raw_id[kb_name])
    # returned answers clause_id
    rowinfo.extend(gr.kb[kb_name].responses.clause_id.iloc[reply_index].tolist())

    cursor.execute('INSERT INTO query_log VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)', rowinfo)
    cursor.commit()

    # 4. Return response to user
    # return id of latest log request to user for when they give feedback
    current_request_id = get_last_insert_ids(cursor)

    return jsonify(responses=reply, query_id=current_request_id)



@app.route("/feedback", methods=['POST'])
def save_feedback():
    """
    Retrieve feedback from end users

    args:
    ----
        query_id: (int) specifies the query to raise feedback for
        is_correct: (list) list fo booleans for true or false
    """
    request_timestamp = datetime.datetime.now()
    request_dict = request.get_json()

    if not all([key in ['query_id', 'is_correct'] for key in request_dict.keys()]):
        raise InvalidUsage("request requires 'query_id', 'is_correct")
    if not (type(request_dict["is_correct"]) == list) & all([type(feedback_)==int for feedback_ in request_dict['is_correct']]):
        raise InvalidUsage("'is_correct' is to contain a list of integers, e.g. {'query_id':45, 'is_correct':[0,1,0,0,0]} indicates that the second ranked answer was correct")

    # 1. parse the request
    query_id = request_dict["query_id"]
    is_correct = request_dict["is_correct"]
    is_correct = is_correct+[False]*(5-len(is_correct)) if len(is_correct) < 5 else is_correct # ensures 5 entries

    # log the request in SQL
    rowinfo = [request_timestamp]
    rowinfo.append(query_id)
    rowinfo.extend(is_correct[:5]) # ensures only 5 values are logged

    cursor.execute('INSERT INTO feedback_log VALUES (?, ?, ?, ?, ?, ?, ?)', rowinfo)
    cursor.commit()

    return jsonify(message="Success")



@app.route("/knowledge_base", methods=['POST'])
def upload_knowledge_base_to_sql():
    """
    Receive knowledge bases from users
    
    args:
    ----
        hashkey: (str, optional) identification; intended to be their hashkey 
                                 to manage exclusive knowledge base access.
        kb_name: (str) Name of knowledge base to save as
        kb: (dict) contains the responses, queries and mappings
                   where mapping maps the indices of (question, answer)


    Sample json body & sample kb:
        {
         'hashkey': HASHKEY,
         'kb_name':'test1',
         'kb':{'responses': ["I'm 21 years old", 
                             "I hate mondays"],
               'contexts': ["Bob", "Gary"],
               'queries': ["What do you not love?", 
                           "How old are you?"],
               'mapping': [(0,1), (1,0)]
              }
        } 
    """
    request_timestamp = datetime.datetime.now()
    request_dict = request.get_json()

    # verify that required arguments are inside
    if not all([key in ['hashkey','kb_name', 'kb'] for key in request_dict.keys()]):
        raise InvalidUsage(message="knowledge_base endpoint requires arguments: hashkey, kb_name, kb")

    HASHKEY = request_dict.get('hashkey', '')
    kb_name = request_dict["kb_name"]
    kb = request_dict["kb"]

    # get user id
    global get_kb_dir_id, get_kb_raw_id, permissions
    try:
        user_id = permissions.loc[HASHKEY].user_id.iloc[-1]
    except:
        print(f"ERROR: Tried to retrieve user id from {HASHKEY}")
        print( permissions.loc[HASHKEY] )
        raise InvalidUsage(message="Hashkey not recognized")



    """
    Load the knowledge base
    """
    # 1a. load to kb_directory
    cursor.execute('INSERT INTO dbo.kb_directory VALUES ( ?, ?, ?)', 
                    [request_timestamp, kb_name, user_id])
    cursor.commit()

    # 1b. get kb_directory index to load into kb_raw
    kb_dir = pds.read_sql("""
                        SELECT * from dbo.kb_directory 
                        WHERE user_id = (?)
                        AND dir_name = (?)
                        """,
                        conn,
                        params = [user_id, kb_name],
                        )
    kb_dir_idx = kb_dir.id.iloc[-1]



    # 2a. load into kb_raw
    # https://stackoverflow.com/questions/41973933/invalid-parameter-type-numpy-int64-when-inserting-rows-with-executemany
    # kb_dir_idx has to be integer typed
    cursor.execute('INSERT INTO dbo.kb_raw VALUES ( ?, ?, ?, ?)', 
                    [None, kb_name, 'user_uploaded', int(kb_dir_idx)])
    cursor.commit()

    # 2b. update SQL references and get kb_raw id
    get_kb_dir_id, get_kb_raw_id, permissions = init_sql_references(conn)
    kb_raw_dir_idx = get_kb_raw_id[kb_name]



    # 3. load into kb_clauses
    responses = kb['responses']
    
    context_strings = kb.get('contexts', [])
    context_strings = ['']*len(responses) if len(context_strings)==0 else context_strings
    if len(context_strings) != len(responses):
        raise InvalidUsage(message="contexts should either have the same number of strings as responses or excluded")

    list_of_clauses = [[kb_raw_dir_idx, clause_ind, context_string, raw_string, context_string + '\n' + raw_string, request_timestamp]
                        for clause_ind, (context_string, raw_string) in enumerate(zip(context_strings, responses))
                        ]

    cursor.executemany('INSERT INTO dbo.kb_clauses VALUES ( ?, ?, ?, ?, ?, ?)', 
                        list_of_clauses)
    cursor.commit()
    idx_of_inserted_clauses = get_last_insert_ids(cursor, list_of_clauses)
    
    print(kb.keys())
    if all(key_ in kb.keys() for key_ in ['queries', 'mapping']):
        if (len(kb['queries'])>0) & (len(kb['mapping'])>0):

            print("loading labels")

            # 4. load into query_db
            cursor.executemany('INSERT INTO dbo.query_db VALUES (?)', 
                                [[query_] for query_ in kb['queries']])
            cursor.commit()
            idx_of_inserted_queries = get_last_insert_ids(cursor, kb['queries'])
    

            # 5. load into query_labels
            #    query labels have the following columns
            #    query_id, clause_id, span_start, span_end, created_at
            mapped_query_ids = pd.Series(idx_of_inserted_queries).iloc[extract(kb['mapping'], idx=0)]
            mapped_clause_ids = pd.Series(idx_of_inserted_clauses).iloc[extract(kb['mapping'], idx=1)]

            list_of_query_labels = [[mapped_query_id, mapped_clause_id , None, None, request_timestamp]
                                    for mapped_query_id, mapped_clause_id
                                    in zip(mapped_query_ids,mapped_clause_ids )
                                    ]

            cursor.executemany('INSERT INTO dbo.query_labels VALUES (?, ?, ?, ?, ?)', 
                                list_of_query_labels)
            cursor.commit()

    # load knowledge base into cached model
    kbs = kbh.load_sql_kb(cnxn_path = args.dir, kb_names=[kb_name])
    gr.load_kb(kbs)

    return jsonify(message="Success")




@app.route("/upload_weights", methods=['POST'])
def upload_weights():
    """
    Upload finetuned weights to an azure blob storage container
    
    args:
    ----
        conn_str: (str) connection string for authorized access to blob storage
        container_name: (str) name of newly created container that will store weights
        blob_name: (str) name to be used for the newly stored weights in the container


    Sample json body:
        {
         'conn_str': CONN_STR,
         'container_name': CONTAINER_NAME,
         'blob_name': BLOB_NAME
        } 
    """

    request_dict = request.form.to_dict()

    if not all([key in ['conn_str', 'container_name', 'blob_name'] for key in request_dict.keys()]):
        raise InvalidUsage(message="upload_weights endpoint requires arguments: conn_str, container_name, blob_name")

    CONN_STR = request.form['conn_str']
    CONTAINER_NAME = request.form['container_name']
    BLOB_NAME = request.form['blob_name']


    # Create the BlobServiceClient that is used to call the Blob service for the storage account
    blob_service_client = BlobServiceClient.from_connection_string(conn_str=CONN_STR)

    # Create a container. Use public_access=PublicAccess.Container if container is open to public
    try:
        blob_service_client.create_container(CONTAINER_NAME, public_access=None)
    except:
        return jsonify(message='Container already exists, please select another container_name and try again')


    # Upload file
    if request.files:
        f = request.files['file']

        # Upload the created file, use WEIGHTS_FOLDER_NAME as the blob name
        blob_client = blob_service_client.get_blob_client(
            container=CONTAINER_NAME, blob=f.filename)

        blob_client.upload_blob(f)

    
    return jsonify(message="Success")


if __name__ == '__main__':
    # app.run(host="0.0.0.0", port="5000")
    serve(app, host='0.0.0.0', port=5000, url_scheme='https')